version: "3.9"
services:
  api:
    image: localai/localai:latest-cpu
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 1m
      timeout: 20m
      retries: 5
    ports:
      - 8888:8080
    environment:
      - DEBUG=true
      - https_proxy=http://10.0.5.196:9090
      - http_proxy=http://10.0.5.196:9090
      # ...
    volumes:
      - localai-models:/build/models:cached

volumes:
  localai-models:
