version: '3.8'

services:
  zoo1:
    image: zookeeper
    networks:
      - kafka
    hostname: zoo1
    ports: # 端口
      - 2181:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181
    volumes:
      - zoo1-conf:/conf
      - zoo1-data:/data
      - zoo1-datalog:/datalog
    deploy:
      mode: replicated
      replicas: 1

  kafka:
    image: wurstmeister/kafka
    depends_on:
      - zoo1
    ports:
      - target: 9094
        published: 9094
        protocol: tcp
        mode: host
    environment:
      # HOSTNAME_COMMAND: "docker info | grep ^Name: | cut -d' ' -f 2"
      HOSTNAME_COMMAND: "docker info -f '{{`{{.Swarm.NodeAddr}}`}}'"
      #BROKER_ID_COMMAND : "docker info -f '{{`{{.Name}}`}}' | sed 's/kafka//g'"
      KAFKA_ZOOKEEPER_CONNECT: zoo1:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://_{HOSTNAME_COMMAND}:9094
      KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true' # 自动创建topics
      KAFKA_LOG_DIRS: /kafka/kafka_log
    #      BROKER_ID_COMMAND: "hostname | awk -F'-' '{print $$2}'" # broker_id 使用hostname的值
    #      KAFKA_BROKER_ID: 1002 # 设置brokerId的值
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - kafka:/kafka
    networks:
      - kafka
    deploy:
      mode: global

  kafka-manager:
    image: hlebalbau/kafka-manager:stable
    ports:
      - "9012:9000"
    depends_on:
      - kafka
    environment:
      ZK_HOSTS: "zoo1:2181"
      APPLICATION_SECRET: "random-secret"
    networks:
      - kafka

volumes:
  zoo1-conf:
    driver: local
  zoo1-data:
    driver: local
  zoo1-datalog:
    driver: local
  kafka:
    driver: local

networks:
  kafka:
    driver: overlay
